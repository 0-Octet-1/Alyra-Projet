#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Interface Streamlit pour l'exploration des donn√©es d'accessibilit√© PMR
Ce script permet d'explorer et visualiser interactivement les donn√©es
g√©n√©r√©es par le script data_preparation_duckdb.py
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import duckdb
import os
import sys
import pickle
from sklearn.pipeline import Pipeline

# Configuration de la page Streamlit
st.set_page_config(
    page_title="Exploration des donn√©es d'accessibilit√© PMR",
    page_icon="‚ôø",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Fonction pour charger les donn√©es (soit les g√©n√©rer, soit les charger depuis les fichiers)
@st.cache_data
def load_data(regenerate=False):
    """
    Charge ou g√©n√®re les donn√©es d'accessibilit√© PMR
    
    Args:
        regenerate: Si True, r√©g√©n√®re les donn√©es m√™me si les fichiers existent
        
    Returns:
        DataFrame pandas contenant les donn√©es
    """
    # Import d√©clar√© en d√©but de fonction pour √©viter les erreurs
    import os
    import sys
    import pickle
    
    # On ajoute le dossier parent (racine du projet) au path Python
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    
    # Chemin des donn√©es pr√©trait√©es
    processed_data_path = os.path.join('..', 'data', 'processed')
    
    # Si les donn√©es n'existent pas ou si on demande une r√©g√©n√©ration
    if regenerate or not os.path.exists(os.path.join(processed_data_path, 'X_train_raw.pkl')):
        st.info("G√©n√©ration de nouvelles donn√©es... (cela peut prendre quelques instants)")
        
        # Import de la fonction de g√©n√©ration depuis notre module
        import sys
        import os
        # On ajoute le dossier parent (racine du projet) au path Python
        sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        # Import direct depuis le module sans utiliser le pr√©fixe 'code'
        from data_preparation_duckdb import generate_synthetic_data, load_data_to_duckdb
        
        # G√©n√©ration des donn√©es
        df = generate_synthetic_data(n_samples=5000)
        
        # Cr√©ation du dossier si n√©cessaire
        os.makedirs(processed_data_path, exist_ok=True)
        
        # Sauvegarde des donn√©es brutes pour r√©f√©rence future
        df.to_pickle(os.path.join(processed_data_path, 'raw_data.pkl'))
        
        return df
    else:
        # Chargement des donn√©es brutes depuis le fichier pickle
        try:
            df = pd.read_pickle(os.path.join(processed_data_path, 'raw_data.pkl'))
            return df
        except Exception as e:
            st.error(f"Erreur lors du chargement des donn√©es: {e}")
            
            # En cas d'erreur, on r√©g√©n√®re les donn√©es
            st.warning("R√©g√©n√©ration des donn√©es...")
            import sys
            import os
            # On ajoute le dossier parent (racine du projet) au path Python
            sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
            # Import direct depuis le module sans utiliser le pr√©fixe 'code'
            from data_preparation_duckdb import generate_synthetic_data
            df = generate_synthetic_data(n_samples=5000)
            return df

# Fonction pour cr√©er et retourner une connexion DuckDB
@st.cache_resource
def get_duckdb_connection(df):
    """
    Cr√©e une connexion DuckDB et charge les donn√©es
    
    Args:
        df: DataFrame pandas √† charger
        
    Returns:
        Connexion DuckDB
    """
    con = duckdb.connect(database=':memory:')
    con.execute("CREATE TABLE IF NOT EXISTS accessibilite_pmr AS SELECT * FROM df")
    return con

# Fonction pour afficher une description compl√®te de la base de donn√©es
def show_database_description(df):
    """
    Affiche une description compl√®te de la base de donn√©es avec:
    - Structure g√©n√©rale
    - Dictionnaire des variables
    - Types et informations manquantes
    - Distribution des classes cibles
    """
    st.header("üìä Description compl√®te de la base de donn√©es")
    
    # Information g√©n√©rale sur le dataset
    st.subheader("Structure g√©n√©rale du dataset")
    st.markdown(f"""
    - **Nombre total d'observations**: {df.shape[0]}
    - **Nombre de variables**: {df.shape[1]}
    - **Variables num√©riques**: {len(df.select_dtypes(include=['float64', 'int64']).columns)}
    - **Variables cat√©gorielles**: {len(df.select_dtypes(include=['object', 'category']).columns)}
    - **M√©moire utilis√©e**: {df.memory_usage().sum() / 1024**2:.2f} MB
    """)
    
    # Afficher les colonnes disponibles pour diagnostic
    st.subheader("Colonnes disponibles dans le dataset")
    st.write(df.columns.tolist())
    
    # V√©rifier si la colonne de classe existe sous un autre nom
    target_column = None
    possible_target_names = ['classe_accessibilite', 'classe', 'accessibilite', 'target', 'label', 'y']
    for column in possible_target_names:
        if column in df.columns:
            target_column = column
            break
    
    # Si on trouve une colonne cible, on affiche sa distribution
    if target_column:
        st.subheader(f"Distribution des classes d'accessibilit√© PMR (colonne: {target_column})")
        fig, ax = plt.subplots(figsize=(10, 6))
        class_counts = df[target_column].value_counts()
        colors = ['#2ecc71', '#f1c40f', '#e74c3c']
        class_counts.plot(kind='bar', ax=ax, color=colors)
        ax.set_xlabel("Classe d'accessibilit√©")
        ax.set_ylabel("Nombre d'observations")
        plt.xticks(rotation=0)
        st.pyplot(fig)
        
        # Distribution en pourcentage si on a les classes attendues
        if len(class_counts) <= 3:
            st.markdown("**Distribution en pourcentage**:")
            for class_name, count in class_counts.items():
                st.markdown(f"- {class_name}: {count / len(df) * 100:.1f}%")
    else:
        st.warning("Colonne de classe d'accessibilit√© non trouv√©e dans le dataset. "
                  "Veuillez v√©rifier le nom de la colonne ou la g√©n√©ration des donn√©es.")
        
        # Affiche un aper√ßu des donn√©es pour un diagnostic plus approfondi
        st.subheader("Aper√ßu des 10 premi√®res lignes (pour diagnostic)")
        st.dataframe(df.head(10))
    
    
    # Dictionnaire des variables
    st.subheader("Dictionnaire des variables")
    variable_dict = {
        "nom_poi": "Nom du point d'int√©r√™t urbain",
        "type_poi": "Type du point d'int√©r√™t (commerce, service public, loisir...)",
        "largeur_trottoir_cm": "Largeur du trottoir d'acc√®s en centim√®tres",
        "presence_rampe": "Pr√©sence d'une rampe d'acc√®s (Oui/Non)",
        "hauteur_marche_cm": "Hauteur de la marche d'entr√©e en centim√®tres",
        "nb_marches": "Nombre de marches √† l'entr√©e",
        "presence_ascenseur": "Pr√©sence d'un ascenseur (Oui/Non)",
        "largeur_porte_cm": "Largeur de la porte d'entr√©e en centim√®tres",
        "type_porte": "Type de porte (manuelle, automatique, battante...)",
        "pente_acces_degres": "Pente d'acc√®s en degr√©s",
        "distance_place_pmr_m": "Distance de la place de stationnement PMR la plus proche en m√®tres",
        "presence_toilettes_pmr": "Pr√©sence de toilettes adapt√©es aux PMR (Oui/Non)",
        "largeur_couloir_cm": "Largeur du couloir principal en centim√®tres",
        "presence_boucle_magnetique": "Pr√©sence d'une boucle magn√©tique pour malentendants (Oui/Non)",
        "presence_signaletique_adaptee": "Pr√©sence d'une signal√©tique adapt√©e (Oui/Non)",
        "contraste_visuel_suffisant": "Contraste visuel suffisant pour malvoyants (Oui/Non)",
        "zone_manoeuvre_fauteuil": "Zone de man≈ìuvre suffisante pour fauteuil roulant (Oui/Non)",
        "personnels_formes": "Personnel form√© √† l'accueil des PMR (Oui/Non)",
        "age_infrastructure_an": "√Çge de l'infrastructure en ann√©es",
        "classe_accessibilite": "Classe d'accessibilit√© PMR (Facilement/Mod√©r√©ment/Difficilement accessible)"
    }
    
    # Cr√©er un DataFrame pour afficher le dictionnaire
    dict_df = pd.DataFrame(list(variable_dict.items()), columns=["Variable", "Description"])
    st.dataframe(dict_df, hide_index=True, width=800)
    
    # Analyse des valeurs manquantes
    st.subheader("Analyse des valeurs manquantes")
    missing_df = pd.DataFrame({
        'Variable': df.columns,
        'Type': df.dtypes.astype(str),
        'Valeurs manquantes': df.isna().sum(),
        'Pourcentage (%)': (df.isna().sum() / len(df) * 100).round(2)
    })
    st.dataframe(missing_df, hide_index=True, width=800)

# Fonction pour afficher les statistiques descriptives
def show_statistics(df, con):
    st.header("üìä Statistiques descriptives")
    
    col1, col2 = st.columns(2)
    
    # Afficher les statistiques des variables num√©riques
    with col1:
        st.subheader("Variables num√©riques")
        st.write(df.describe())
    
    # Afficher la distribution de la variable cible
    with col2:
        st.subheader("Distribution des classes d'accessibilit√©")
        target_dist = con.execute("""
            SELECT 
                accessibilite, 
                COUNT(*) as nombre, 
                (COUNT(*) * 100.0 / (SELECT COUNT(*) FROM accessibilite_pmr)) as pourcentage
            FROM accessibilite_pmr
            GROUP BY accessibilite
            ORDER BY nombre DESC
        """).fetchdf()
        
        st.dataframe(target_dist)
        
        # Cr√©er un graphique pie pour la distribution
        fig, ax = plt.subplots(figsize=(8, 8))
        ax.pie(
            target_dist['pourcentage'], 
            labels=target_dist['accessibilite'], 
            autopct='%1.1f%%',
            startangle=90,
            shadow=True,
            explode=[0.05 if x == 'Difficilement_Accessible' else 0 for x in target_dist['accessibilite']]
        )
        ax.axis('equal')  # Aspect ratio √©gal pour un cercle
        st.pyplot(fig)

# Fonction pour afficher les corr√©lations
def show_correlations(df):
    st.header("üîÑ Analyse des corr√©lations")
    
    # R√©cup√©rer le nom de la colonne cible s'il existe
    target_column = None
    possible_target_names = ['classe_accessibilite', 'classe', 'accessibilite', 'target', 'label', 'y']
    for column in possible_target_names:
        if column in df.columns:
            target_column = column
            break
    
    # S√©lectionner uniquement les colonnes num√©riques
    num_columns = df.select_dtypes(include=['int64', 'float64']).columns
    
    # Calculer la matrice de corr√©lation
    corr_matrix = df[num_columns].corr()
    
    # Options pour la visualisation des corr√©lations
    st.subheader("Options de visualisation")
    col1, col2 = st.columns(2)
    
    with col1:
        corr_threshold = st.slider(
            "Seuil minimum de corr√©lation",
            min_value=0.0,
            max_value=1.0,
            value=0.1,
            step=0.05,
            help="Masquer les corr√©lations inf√©rieures √† cette valeur absolue"
        )
    
    with col2:
        mask_option = st.radio(
            "Masquage de la matrice",
            options=["Afficher tout", "Masquer la diagonale", "Masquer le triangle inf√©rieur"],
            index=2,
            horizontal=True
        )
    
    # Cr√©er un masque selon l'option choisie
    mask = None
    if mask_option == "Masquer la diagonale":
        mask = np.eye(len(corr_matrix))
    elif mask_option == "Masquer le triangle inf√©rieur":
        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
    
    # Appliquer un seuil aux corr√©lations faibles
    if corr_threshold > 0:
        # Cr√©er une copie pour l'affichage
        display_matrix = corr_matrix.copy()
        # Remplacer les corr√©lations faibles par NaN pour qu'elles soient transparentes dans le heatmap
        display_matrix[abs(display_matrix) < corr_threshold] = np.nan
    else:
        display_matrix = corr_matrix
    
    # Afficher la matrice de corr√©lation sous forme de heatmap am√©lior√©
    st.subheader("Matrice de corr√©lation")
    fig, ax = plt.subplots(figsize=(12, 10))
    
    # Utiliser un meilleur colormap et plus d'options
    sns.heatmap(
        display_matrix,
        mask=mask,
        annot=True,  # Afficher les valeurs
        cmap='coolwarm',  # Colormap rouge-bleu
        fmt=".2f",  # Format √† deux d√©cimales
        ax=ax,
        center=0,  # Centrer la colormap √† z√©ro
        square=True,  # Cellules carr√©es
        linewidths=0.5,  # Lignes entre les cellules
        cbar_kws={"shrink": 0.8, "label": "Coefficient de corr√©lation"}
    )
    
    # Rotation des √©tiquettes pour une meilleure lisibilit√©
    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)
    plt.tight_layout()
    
    st.pyplot(fig)
    
    # Analyse textuelle des corr√©lations les plus fortes
    st.subheader("Corr√©lations importantes")
    
    # Convertir la matrice en un format tabulaire pour analyse
    corr_df = corr_matrix.unstack().reset_index()
    corr_df.columns = ['Feature 1', 'Feature 2', 'Correlation']
    
    # Filtrer pour enlever les auto-corr√©lations et les duplications
    corr_df = corr_df[
        (corr_df['Feature 1'] != corr_df['Feature 2']) &  # Enlever auto-corr√©lations
        (abs(corr_df['Correlation']) >= corr_threshold)  # Appliquer le seuil
    ]
    
    # Trier par corr√©lation absolue
    corr_df['Abs_Correlation'] = abs(corr_df['Correlation'])
    corr_df = corr_df.sort_values('Abs_Correlation', ascending=False)
    corr_df = corr_df.drop('Abs_Correlation', axis=1)
    
    # Enlever les duplications (la corr√©lation entre A et B est la m√™me qu'entre B et A)
    corr_df['Pair'] = corr_df.apply(lambda x: '_'.join(sorted([x['Feature 1'], x['Feature 2']])), axis=1)
    corr_df = corr_df.drop_duplicates('Pair').drop('Pair', axis=1)
    
    # Afficher les corr√©lations les plus fortes
    st.dataframe(corr_df.head(15), hide_index=True, width=800)
    
    # Afficher l'interpr√©tation des corr√©lations
    st.subheader("Interpr√©tation des corr√©lations")
    st.write("""
    - **Corr√©lation positive forte** (proche de 1) : Lorsqu'une variable augmente, l'autre augmente √©galement de fa√ßon proportionnelle
    - **Corr√©lation n√©gative forte** (proche de -1) : Lorsqu'une variable augmente, l'autre diminue de fa√ßon proportionnelle
    - **Corr√©lation proche de 0** : Pas de relation lin√©aire entre les variables
    """)
    
    # Si on a une colonne cible, montrer les corr√©lations avec cette colonne sp√©cifiquement
    if target_column and target_column in df.columns and df[target_column].dtype.name in ['category', 'object']:
        st.subheader(f"Relation entre les caract√©ristiques num√©riques et la classe d'accessibilit√©")
        
        # One-hot encode la colonne cible pour calculer les corr√©lations
        target_dummies = pd.get_dummies(df[target_column], prefix='class')
        
        # Fusionner avec les variables num√©riques
        extended_df = pd.concat([df[num_columns], target_dummies], axis=1)
        
        # Calculer les nouvelles corr√©lations
        target_corr = extended_df.corr().loc[num_columns, target_dummies.columns]
        
        # Afficher les corr√©lations tri√©es en barplot horizontal
        fig, axes = plt.subplots(1, len(target_dummies.columns), figsize=(15, 8))
        
        # Si une seule classe, axes n'est pas un it√©rable
        if len(target_dummies.columns) == 1:
            axes = [axes]
            
        for i, class_col in enumerate(target_dummies.columns):
            # Trier les corr√©lations
            class_corrs = target_corr[class_col].sort_values(ascending=False)
            
            # Plot horizontal bar chart
            class_corrs.plot(kind='barh', ax=axes[i], color='skyblue')
            axes[i].set_title(f"Corr√©lations avec {class_col}")
            axes[i].axvline(x=0, color='black', linestyle='-', alpha=0.3)
            
            # Ajouter les valeurs sur les barres
            for j, v in enumerate(class_corrs):
                axes[i].text(v + (0.01 if v >= 0 else -0.05), j, f"{v:.2f}", va='center')
        
        plt.tight_layout()
        st.pyplot(fig)
        
        st.write("""
        Ce graphique montre les caract√©ristiques les plus pr√©dictives pour chaque classe d'accessibilit√©.
        Les valeurs positives indiquent qu'une valeur √©lev√©e de la caract√©ristique est associ√©e √† cette classe,
        tandis que les valeurs n√©gatives indiquent une relation inverse.
        """)
        

# Fonction pour afficher les visualisations
def show_visualizations(df):
    st.header("üìà Visualisations")
    
    # S√©lection du type de visualisation
    viz_type = st.selectbox(
        "Choisir un type de visualisation",
        ["Distribution des variables num√©riques", "Relations avec la classe d'accessibilit√©", "Croisements cat√©goriels"]
    )
    
    if viz_type == "Distribution des variables num√©riques":
        # S√©lectionner la variable √† visualiser
        num_columns = df.select_dtypes(include=['int64', 'float64']).columns
        selected_var = st.selectbox("S√©lectionner une variable", num_columns)
        
        # Cr√©ation de la figure
        fig, ax = plt.subplots(1, 2, figsize=(16, 6))
        
        # Histogramme
        sns.histplot(df[selected_var], kde=True, ax=ax[0])
        ax[0].set_title(f'Distribution de {selected_var}')
        
        # Boxplot par classe d'accessibilit√©
        sns.boxplot(x='accessibilite', y=selected_var, data=df, ax=ax[1])
        ax[1].set_title(f'{selected_var} par classe d\'accessibilit√©')
        ax[1].tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        st.pyplot(fig)
        
    elif viz_type == "Relations avec la classe d'accessibilit√©":
        # Cr√©er des paires de visualisations pour les variables num√©riques par rapport √† la classe
        num_columns = df.select_dtypes(include=['int64', 'float64']).columns
        selected_vars = st.multiselect(
            "S√©lectionner les variables √† comparer (max 3 recommand√©)",
            num_columns,
            default=list(num_columns[:2])
        )
        
        if selected_vars:
            fig, ax = plt.subplots(1, len(selected_vars), figsize=(5*len(selected_vars), 5))
            
            # Si une seule variable est s√©lectionn√©e, ax n'est pas un tableau
            if len(selected_vars) == 1:
                ax = [ax]
            
            for i, var in enumerate(selected_vars):
                sns.boxplot(x='accessibilite', y=var, data=df, ax=ax[i])
                ax[i].set_title(f'{var} par classe')
                ax[i].tick_params(axis='x', rotation=45)
            
            plt.tight_layout()
            st.pyplot(fig)
        
    else:  # Croisements cat√©goriels
        # S√©lectionner deux variables cat√©gorielles √† croiser
        cat_columns = df.select_dtypes(include=['object']).columns.tolist()
        cat_columns.remove('accessibilite')  # On retire la variable cible
        
        col1, col2 = st.columns(2)
        with col1:
            cat_var1 = st.selectbox("Premi√®re variable", cat_columns)
        with col2:
            cat_var2 = st.selectbox("Deuxi√®me variable", cat_columns, index=1 if len(cat_columns) > 1 else 0)
        
        # Tableau crois√©
        cross_tab = pd.crosstab(df[cat_var1], df[cat_var2])
        st.write(cross_tab)
        
        # Visualisation sous forme de heatmap
        fig, ax = plt.subplots(figsize=(10, 8))
        sns.heatmap(cross_tab, annot=True, fmt='d', cmap='viridis', ax=ax)
        plt.title(f'Tableau crois√©: {cat_var1} vs {cat_var2}')
        st.pyplot(fig)

# Fonction pour afficher la requ√™te DuckDB personnalis√©e
def show_custom_query(con):
    st.header("üîç Requ√™te DuckDB personnalis√©e")
    
    # Zone de texte pour entrer une requ√™te SQL personnalis√©e
    default_query = "SELECT type_lieu, accessibilite, COUNT(*) as nombre FROM accessibilite_pmr GROUP BY type_lieu, accessibilite ORDER BY type_lieu, accessibilite"
    query = st.text_area("Entrer une requ√™te SQL personnalis√©e", default_query, height=100)
    
    if st.button("Ex√©cuter la requ√™te"):
        try:
            # Ex√©cuter la requ√™te et r√©cup√©rer les r√©sultats
            result = con.execute(query).fetchdf()
            
            # Afficher les r√©sultats sous forme de tableau
            st.dataframe(result)
            
            # Si la requ√™te renvoie des donn√©es num√©riques, proposer une visualisation
            if len(result.columns) >= 2 and result.shape[0] > 1:
                if st.checkbox("Visualiser les r√©sultats"):
                    # Tenter de d√©terminer le meilleur type de graphique
                    fig, ax = plt.subplots(figsize=(10, 6))
                    
                    if result.shape[0] <= 20 and result.select_dtypes(include=['int64', 'float64']).shape[1] >= 1:
                        # Trouver une colonne num√©rique pour le graphique
                        num_cols = result.select_dtypes(include=['int64', 'float64']).columns
                        if len(num_cols) > 0:
                            # Utiliser un barplot pour visualiser
                            result.plot(kind='bar', x=result.columns[0], y=num_cols[0], ax=ax)
                            plt.title(f'Visualisation de {num_cols[0]} par {result.columns[0]}')
                            plt.xticks(rotation=45)
                            st.pyplot(fig)
        
        except Exception as e:
            st.error(f"Erreur d'ex√©cution de la requ√™te: {e}")

# Fonction principale pour l'application Streamlit
def main():
    st.title("‚ôø Exploration des donn√©es d'accessibilit√© PMR")
    st.markdown("""
    Cette application permet d'explorer et visualiser les donn√©es du projet d'accessibilit√© PMR,
    en utilisant DuckDB comme moteur de requ√™tes pour une analyse rapide et efficace.
    """)
    
    # Barre lat√©rale avec options
    st.sidebar.title("Options")
    regenerate_data = st.sidebar.checkbox("R√©g√©n√©rer les donn√©es")
    
    # Charger les donn√©es
    df = load_data(regenerate=regenerate_data)
    
    # Cr√©er une connexion DuckDB
    con = get_duckdb_connection(df)
    
    # Afficher un aper√ßu des donn√©es
    st.header("üìÑ Aper√ßu des donn√©es")
    st.dataframe(df.head())
    
    st.markdown(f"**{df.shape[0]} exemples** avec **{df.shape[1]} caract√©ristiques**")
    
    # Navigation par onglets avec Description comme premier onglet
    tab0, tab1, tab2, tab3, tab4 = st.tabs(["Description", "Statistiques", "Corr√©lations", "Visualisations", "Requ√™tes SQL"])
    
    with tab0:
        show_database_description(df)
    
    with tab1:
        show_statistics(df, con)
    
    with tab2:
        show_correlations(df)
    
    with tab3:
        show_visualizations(df)
    
    with tab4:
        show_custom_query(con)

if __name__ == "__main__":
    main()
