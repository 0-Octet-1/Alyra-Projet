#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
API FastAPI pour la pr√©diction d'accessibilit√© PMR
Projet PMR - Certification D√©veloppeur IA

API REST pour pr√©dire l'accessibilit√© PMR de points d'int√©r√™t urbains
Utilise le meilleur mod√®le Deep Learning (MLP Profond - F1: 94.4%)

Auteur: 0-Octet-1
Date: 8 juillet 2025
"""

import os
import sys
import pickle
import json
import numpy as np
import pandas as pd
from datetime import datetime
from typing import List, Dict, Optional
import warnings
warnings.filterwarnings('ignore')

# FastAPI imports
from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, JSONResponse
from pydantic import BaseModel, Field, validator
import uvicorn

# Configuration des chemins
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
MODELS_DIR = os.path.join(PROJECT_ROOT, 'models')
DATA_DIR = os.path.join(PROJECT_ROOT, 'data')

# Configuration de l'API
app = FastAPI(
    title="API PMR - Pr√©diction d'Accessibilit√©",
    description="API REST pour pr√©dire l'accessibilit√© PMR de points d'int√©r√™t urbains",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Configuration CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Variables globales pour les mod√®les
model_ml = None
model_dl = None
preprocessor = None
feature_names = None
model_info = {}

class PMRFeatures(BaseModel):
    """Mod√®le Pydantic pour les features d'entr√©e"""
    
    # Features principales
    largeur_trottoir: float = Field(..., ge=0.0, le=10.0, description="Largeur du trottoir en m√®tres")
    hauteur_bordure: float = Field(..., ge=0.0, le=0.5, description="Hauteur de la bordure en m√®tres")
    pente_acces: float = Field(..., ge=0.0, le=45.0, description="Pente d'acc√®s en degr√©s")
    distance_transport: float = Field(..., ge=0.0, le=2000.0, description="Distance aux transports en m√®tres")
    eclairage_qualite: int = Field(..., ge=1, le=5, description="Qualit√© de l'√©clairage (1-5)")
    surface_qualite: int = Field(..., ge=1, le=5, description="Qualit√© de la surface (1-5)")
    signalisation_presence: int = Field(..., ge=0, le=1, description="Pr√©sence de signalisation (0/1)")
    obstacles_nombre: int = Field(..., ge=0, le=20, description="Nombre d'obstacles")
    rampe_presence: int = Field(..., ge=0, le=1, description="Pr√©sence de rampe (0/1)")
    places_pmr_nombre: int = Field(..., ge=0, le=50, description="Nombre de places PMR")
    type_poi: str = Field(..., description="Type de point d'int√©r√™t")
    
    @validator('type_poi')
    def validate_type_poi(cls, v):
        valid_types = ['restaurant', 'magasin', 'service_public', 'transport', 'loisir']
        if v.lower() not in valid_types:
            raise ValueError(f'Type POI doit √™tre un de: {valid_types}')
        return v.lower()

class PredictionResponse(BaseModel):
    """Mod√®le de r√©ponse pour les pr√©dictions"""
    
    prediction: int = Field(..., description="Classe pr√©dite (0: Non accessible, 1: Partiellement accessible, 2: Accessible)")
    prediction_label: str = Field(..., description="Label de la pr√©diction")
    confidence: float = Field(..., description="Confiance de la pr√©diction (0-1)")
    probabilities: Dict[str, float] = Field(..., description="Probabilit√©s pour chaque classe")
    model_used: str = Field(..., description="Mod√®le utilis√© pour la pr√©diction")
    timestamp: str = Field(..., description="Timestamp de la pr√©diction")

class BatchPredictionRequest(BaseModel):
    """Mod√®le pour les pr√©dictions en lot"""
    
    features_list: List[PMRFeatures] = Field(..., description="Liste des features √† pr√©dire")
    model_type: Optional[str] = Field("dl", description="Type de mod√®le (ml/dl)")

def load_models():
    """Charge les mod√®les et le preprocesseur"""
    global model_ml, model_dl, preprocessor, feature_names, model_info
    
    try:
        # Charger le meilleur mod√®le DL (MLP Profond)
        dl_files = [f for f in os.listdir(MODELS_DIR) if f.startswith('mlp_mlp_profond_') and f.endswith('.pkl')]
        if dl_files:
            latest_dl_file = sorted(dl_files)[-1]
            dl_path = os.path.join(MODELS_DIR, latest_dl_file)
            
            with open(dl_path, 'rb') as f:
                model_dl = pickle.load(f)
            
            print(f"‚úÖ Mod√®le DL charg√©: {latest_dl_file}")
        
        # Charger le meilleur mod√®le ML (Random Forest)
        ml_files = [f for f in os.listdir(MODELS_DIR) if f.startswith('random_forest_') and f.endswith('.pkl')]
        if ml_files:
            latest_ml_file = sorted(ml_files)[-1]
            ml_path = os.path.join(MODELS_DIR, latest_ml_file)
            
            with open(ml_path, 'rb') as f:
                model_ml = pickle.load(f)
            
            print(f"‚úÖ Mod√®le ML charg√©: {latest_ml_file}")
        
        # Charger les informations des mod√®les
        results_files = [f for f in os.listdir(MODELS_DIR) if f.startswith('mlp_results_') and f.endswith('.json')]
        if results_files:
            latest_results_file = sorted(results_files)[-1]
            results_path = os.path.join(MODELS_DIR, latest_results_file)
            
            with open(results_path, 'r') as f:
                model_info = json.load(f)
        
        # D√©finir les noms des features
        feature_names = [
            'largeur_trottoir', 'hauteur_bordure', 'pente_acces', 'distance_transport',
            'eclairage_qualite', 'surface_qualite', 'signalisation_presence',
            'obstacles_nombre', 'rampe_presence', 'places_pmr_nombre',
            'type_poi_loisir', 'type_poi_magasin', 'type_poi_restaurant',
            'type_poi_service_public', 'type_poi_transport'
        ]
        
        print("‚úÖ Mod√®les et informations charg√©s avec succ√®s")
        
    except Exception as e:
        print(f"‚ùå Erreur lors du chargement des mod√®les: {e}")
        raise

def preprocess_features(features: PMRFeatures) -> np.ndarray:
    """Pr√©processe les features pour la pr√©diction"""
    
    # Cr√©er le vecteur de features
    feature_vector = [
        features.largeur_trottoir,
        features.hauteur_bordure,
        features.pente_acces,
        features.distance_transport,
        features.eclairage_qualite,
        features.surface_qualite,
        features.signalisation_presence,
        features.obstacles_nombre,
        features.rampe_presence,
        features.places_pmr_nombre
    ]
    
    # One-hot encoding pour type_poi
    poi_types = ['loisir', 'magasin', 'restaurant', 'service_public', 'transport']
    for poi_type in poi_types:
        feature_vector.append(1 if features.type_poi == poi_type else 0)
    
    return np.array(feature_vector).reshape(1, -1)

def get_prediction_label(prediction: int) -> str:
    """Convertit la pr√©diction num√©rique en label"""
    labels = {
        0: "Non accessible",
        1: "Partiellement accessible", 
        2: "Accessible"
    }
    return labels.get(prediction, "Inconnu")

# √âv√©nements de d√©marrage
@app.on_event("startup")
async def startup_event():
    """Charge les mod√®les au d√©marrage de l'API"""
    print("üöÄ D√©marrage de l'API PMR...")
    load_models()
    print("‚úÖ API PMR pr√™te !")

# Routes de l'API

@app.get("/", response_class=HTMLResponse)
async def root():
    """Page d'accueil de l'API"""
    html_content = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>API PMR - Pr√©diction d'Accessibilit√©</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 40px; background-color: #f5f5f5; }
            .container { max-width: 800px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
            h1 { color: #2c3e50; text-align: center; }
            .info { background: #e8f4fd; padding: 20px; border-radius: 5px; margin: 20px 0; }
            .endpoint { background: #f8f9fa; padding: 15px; margin: 10px 0; border-left: 4px solid #007bff; }
            .method { font-weight: bold; color: #007bff; }
            a { color: #007bff; text-decoration: none; }
            a:hover { text-decoration: underline; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ü¶Ω API PMR - Pr√©diction d'Accessibilit√©</h1>
            
            <div class="info">
                <h3>üìä Informations sur les Mod√®les</h3>
                <p><strong>Meilleur Mod√®le:</strong> MLP Profond (Deep Learning)</p>
                <p><strong>Performance:</strong> F1-score macro: 94.4%</p>
                <p><strong>Accuracy:</strong> 97.5%</p>
            </div>
            
            <h3>üîó Endpoints Disponibles</h3>
            
            <div class="endpoint">
                <span class="method">GET</span> <code>/health</code> - V√©rifier l'√©tat de l'API
            </div>
            
            <div class="endpoint">
                <span class="method">GET</span> <code>/models/info</code> - Informations sur les mod√®les
            </div>
            
            <div class="endpoint">
                <span class="method">POST</span> <code>/predict</code> - Pr√©diction simple
            </div>
            
            <div class="endpoint">
                <span class="method">POST</span> <code>/predict/batch</code> - Pr√©dictions en lot
            </div>
            
            <h3>üìö Documentation</h3>
            <p>
                <a href="/docs" target="_blank">üìñ Documentation Swagger</a> | 
                <a href="/redoc" target="_blank">üìã Documentation ReDoc</a>
            </p>
            
            <div class="info">
                <h4>üéØ Classes de Pr√©diction</h4>
                <ul>
                    <li><strong>0:</strong> Non accessible</li>
                    <li><strong>1:</strong> Partiellement accessible</li>
                    <li><strong>2:</strong> Accessible</li>
                </ul>
            </div>
        </div>
    </body>
    </html>
    """
    return HTMLResponse(content=html_content)

@app.get("/health")
async def health_check():
    """V√©rification de l'√©tat de l'API"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "models_loaded": {
            "ml_model": model_ml is not None,
            "dl_model": model_dl is not None
        },
        "version": "1.0.0"
    }

@app.get("/models/info")
async def get_models_info():
    """Informations sur les mod√®les charg√©s"""
    return {
        "models_available": {
            "ml_model": "Random Forest" if model_ml else None,
            "dl_model": "MLP Profond" if model_dl else None
        },
        "performance": model_info.get("models", {}),
        "feature_names": feature_names,
        "classes": {
            0: "Non accessible",
            1: "Partiellement accessible",
            2: "Accessible"
        }
    }

@app.post("/predict", response_model=PredictionResponse)
async def predict_single(features: PMRFeatures, model_type: str = "dl"):
    """Pr√©diction simple pour un point d'int√©r√™t"""
    
    try:
        # S√©lectionner le mod√®le
        if model_type.lower() == "dl" and model_dl is not None:
            model = model_dl
            model_name = "MLP Profond (Deep Learning)"
        elif model_type.lower() == "ml" and model_ml is not None:
            model = model_ml
            model_name = "Random Forest (Machine Learning)"
        else:
            raise HTTPException(status_code=400, detail="Mod√®le non disponible")
        
        # Pr√©processer les features
        X = preprocess_features(features)
        
        # Faire la pr√©diction
        prediction = model.predict(X)[0]
        
        # Obtenir les probabilit√©s
        if hasattr(model, 'predict_proba'):
            probabilities = model.predict_proba(X)[0]
            confidence = float(np.max(probabilities))
            
            prob_dict = {
                "Non accessible": float(probabilities[0]),
                "Partiellement accessible": float(probabilities[1]),
                "Accessible": float(probabilities[2])
            }
        else:
            confidence = 0.95  # Valeur par d√©faut
            prob_dict = {"prediction": float(prediction)}
        
        return PredictionResponse(
            prediction=int(prediction),
            prediction_label=get_prediction_label(int(prediction)),
            confidence=confidence,
            probabilities=prob_dict,
            model_used=model_name,
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur lors de la pr√©diction: {str(e)}")

@app.post("/predict/batch")
async def predict_batch(request: BatchPredictionRequest):
    """Pr√©dictions en lot"""
    
    try:
        # S√©lectionner le mod√®le
        model_type = request.model_type.lower()
        if model_type == "dl" and model_dl is not None:
            model = model_dl
            model_name = "MLP Profond (Deep Learning)"
        elif model_type == "ml" and model_ml is not None:
            model = model_ml
            model_name = "Random Forest (Machine Learning)"
        else:
            raise HTTPException(status_code=400, detail="Mod√®le non disponible")
        
        predictions = []
        
        for features in request.features_list:
            # Pr√©processer les features
            X = preprocess_features(features)
            
            # Faire la pr√©diction
            prediction = model.predict(X)[0]
            
            # Obtenir les probabilit√©s
            if hasattr(model, 'predict_proba'):
                probabilities = model.predict_proba(X)[0]
                confidence = float(np.max(probabilities))
                
                prob_dict = {
                    "Non accessible": float(probabilities[0]),
                    "Partiellement accessible": float(probabilities[1]),
                    "Accessible": float(probabilities[2])
                }
            else:
                confidence = 0.95
                prob_dict = {"prediction": float(prediction)}
            
            predictions.append({
                "prediction": int(prediction),
                "prediction_label": get_prediction_label(int(prediction)),
                "confidence": confidence,
                "probabilities": prob_dict
            })
        
        return {
            "predictions": predictions,
            "model_used": model_name,
            "total_predictions": len(predictions),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur lors des pr√©dictions: {str(e)}")

@app.get("/predict/example")
async def get_prediction_example():
    """Exemple de donn√©es pour tester l'API"""
    return {
        "example_request": {
            "largeur_trottoir": 2.5,
            "hauteur_bordure": 0.15,
            "pente_acces": 5.0,
            "distance_transport": 150.0,
            "eclairage_qualite": 4,
            "surface_qualite": 4,
            "signalisation_presence": 1,
            "obstacles_nombre": 2,
            "rampe_presence": 1,
            "places_pmr_nombre": 3,
            "type_poi": "restaurant"
        },
        "curl_example": """
curl -X POST "http://localhost:8000/predict" \\
     -H "Content-Type: application/json" \\
     -d '{
       "largeur_trottoir": 2.5,
       "hauteur_bordure": 0.15,
       "pente_acces": 5.0,
       "distance_transport": 150.0,
       "eclairage_qualite": 4,
       "surface_qualite": 4,
       "signalisation_presence": 1,
       "obstacles_nombre": 2,
       "rampe_presence": 1,
       "places_pmr_nombre": 3,
       "type_poi": "restaurant"
     }'
        """
    }

if __name__ == "__main__":
    print("üöÄ Lancement de l'API PMR...")
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
